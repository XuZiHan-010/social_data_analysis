# social_data_analysis

æ¨¡æ‹Ÿç¤¾äº¤å¹³å°é€šä¿¡æ—¥å¿—å¤§æ•°æ®åˆ†æç³»ç»Ÿï¼ˆHive + FineBIï¼‰ 
Simulated Social Platform Communication Log Big Data Analysis System (Hive + FineBI)

æœ¬é¡¹ç›®åŸºäº Hive æ•°æ®ä»“åº“ä¸ FineBI å¯è§†åŒ–å¹³å°ï¼Œæ„å»ºäº†ä¸€ä¸ªæ¨¡æ‹Ÿçš„é€šä¿¡æ—¥å¿—åˆ†æç³»ç»Ÿã€‚é€šè¿‡ Python æ¨¡æ‹Ÿç”Ÿæˆç™¾ä¸‡çº§é€šä¿¡æ•°æ®ï¼Œä½¿ç”¨ HiveSQL è¿›è¡Œæ•°æ®æ¸…æ´—å’Œç»Ÿè®¡ï¼Œæœ€ç»ˆåœ¨ FineBI ä¸Šå±•ç¤ºç”¨æˆ·åˆ†å¸ƒã€é€šä¿¡é¢‘ç‡ã€çƒ­é—¨ç”¨æˆ·ç­‰å¯è§†åŒ–æŠ¥è¡¨ã€‚
This project builds a simulated communication log analysis system based on the Hive data warehouse and the FineBI visualization platform. Using Python, we generated millions of communication records. HiveSQL was then applied for data cleaning and aggregation, and FineBI was used to visualize user distribution, communication frequency, top users, and more.



ğŸ“ é¡¹ç›®ç»“æ„

data_generator.pyï¼šç”¨äºç”Ÿæˆ 100 ä¸‡çº§é€šä¿¡æ•°æ®çš„ Python è„šæœ¬ï¼ŒåŒ…å«ä¸­æ–‡å§“åã€GPSã€é€šä¿¡å†…å®¹ç­‰å­—æ®µã€‚

china_province.py: ä¸ºäº†åœ¨ Hive SQL ä¸­æ ¹æ®ç»çº¬åº¦åˆ¤æ–­æ¯æ¡æ¶ˆæ¯å±äºå“ªä¸ªçœä»½ï¼Œæœ¬é¡¹ç›®ä½¿ç”¨ä»¥ä¸‹ Python è„šæœ¬è¯»å– china_province.json GeoJSON æ–‡ä»¶ï¼Œå¹¶æå–å„çœçš„ç»çº¬åº¦èŒƒå›´ï¼ˆbounding boxï¼‰ï¼š

hive_sql/ï¼šHive è¡¨çš„åˆ›å»ºã€æ¸…æ´—ã€ç»Ÿè®¡ SQL è„šæœ¬ï¼Œé€‚é… FineBI ä½¿ç”¨ã€‚

README.mdï¼šé¡¹ç›®è¯´æ˜æ–‡æ¡£ã€‚

screenshots/ï¼šFineBI æŠ¥è¡¨æˆªå›¾ã€‚
Project Structure
data_generator.py: A Python script that generates 1 million+ simulated communication records, including Chinese names, GPS coordinates, message content, and more.

china_province.py: To identify which province each message belongs to based on its GPS coordinates, this Python script reads from a china_province.json GeoJSON file and extracts the bounding boxes (latitude and longitude ranges) for each province.

hive_sql/: Contains SQL scripts for creating Hive tables, cleaning the data, and performing statistical analysis. These scripts are optimized for use with FineBI.

README.md: Project documentation.

screenshots/: Contains screenshots of the FineBI dashboards and visual reports.

ğŸ—ï¸ Hadoop åˆ†å¸ƒå¼ç¯å¢ƒæ”¯æŒ

æœ¬é¡¹ç›®æ„å»ºåœ¨ Hadoop 3.3.6 åˆ†å¸ƒå¼æ•°æ®å¤„ç†å¹³å°ä¹‹ä¸Šï¼š

æ­å»ºäº†åŒ…å« node1ï¼ˆä¸»èŠ‚ç‚¹ï¼‰ã€node2ã€node3 çš„ä¼ªåˆ†å¸ƒå¼é›†ç¾¤ã€‚

æ‰€æœ‰ Hive è¡¨çš„æ•°æ®å­˜å‚¨åœ¨ HDFS ä¸Šï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®çš„é«˜æ•ˆè¯»å†™ã€‚

Hive å…ƒæ•°æ®ç”± Metastore ç»´æŠ¤ï¼Œéƒ¨ç½²åœ¨ node1ï¼Œå¹¶é€šè¿‡ JDBC ä¾› DataGrip ä¸ FineBI è¿œç¨‹è®¿é—®ã€‚

MapReduce å¼•æ“æ”¯æ’‘äº† HiveSQL çš„åº•å±‚æŸ¥è¯¢æ‰§è¡Œï¼Œæé«˜äº†ç™¾ä¸‡çº§æ•°æ®çš„å¤„ç†æ•ˆç‡ã€‚

ğŸ” æ•°æ®å¤„ç†æµç¨‹

ä½¿ç”¨ Python Faker æ¨¡æ‹Ÿç”Ÿæˆ CSV æ ¼å¼çš„é€šä¿¡æ—¥å¿—æ•°æ®ï¼ˆåŒ…å« null å€¼ã€å¼‚å¸¸ç»çº¬åº¦ã€ä¸åŒæœºå‹ç­‰ï¼‰ã€‚

é€šè¿‡ Hive LOAD DATA å¯¼å…¥æ•°æ®è‡³å†…éƒ¨è¡¨å¹¶åˆ›å»ºæ¸…æ´—è¡¨ç»“æ„ã€‚

æ‰§è¡Œ HiveSQL å¯¹æ•°æ®è¿›è¡Œåˆ†çœåˆ’åˆ†ã€ç»Ÿè®¡åˆ†æã€TOP ç”¨æˆ·æå–ç­‰ã€‚

ä½¿ç”¨ DataGrip ç¼–å†™å¹¶æµ‹è¯• SQLï¼Œç¡®ä¿æŸ¥è¯¢æ€§èƒ½ä¸æ­£ç¡®æ€§ã€‚

åœ¨ FineBI ä¸­æ¥å…¥ Hive è¡¨ï¼Œè®¾è®¡åœ°å›¾ã€é›·è¾¾å›¾ã€æŸ±çŠ¶å›¾ç­‰æŠ¥è¡¨å®ç°æ•°æ®å¯è§†åŒ–ã€‚

ğŸ“ˆ å¯è§†åŒ–äº®ç‚¹ï¼ˆFineBIï¼‰

é€šä¿¡ç”¨æˆ·åœ°åŸŸåˆ†å¸ƒå›¾ï¼ˆåŸºäºç»çº¬åº¦åŒ¹é…çœä»½ï¼‰ã€‚

æœˆåº¦çƒ­é—¨å‘é€ç”¨æˆ· TOP5 é›·è¾¾å›¾ï¼ˆæ”¯æŒæœˆä»½åˆ‡æ¢ï¼‰ã€‚

æ¯æœˆæ”¶å‘ç”¨æˆ·æ•°é‡ç»Ÿè®¡å›¾ï¼ˆæŸ±çŠ¶å›¾ï¼‰ã€‚

ğŸ“¦ ç¯å¢ƒè¯´æ˜

Hadoop: 3.3.6

Hive: æ”¯æŒ Beeline è¿œç¨‹è¿æ¥

Python: 3.10ï¼Œä¾èµ– Fakerã€csv

FineBI: æœ¬åœ°éƒ¨ç½²ï¼Œè¿æ¥ Hive Metastore

DataGrip: ç¼–å†™å¹¶éªŒè¯ HiveSQL æŸ¥è¯¢

ç³»ç»Ÿç¯å¢ƒ: Ubuntu è™šæ‹Ÿæœºï¼ˆHive å’Œ Hadoop éƒ¨ç½²ï¼‰
